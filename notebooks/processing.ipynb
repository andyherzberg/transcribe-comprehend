{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Processing\n",
    "\n",
    "This notebook shows a basic sequence of processing steps required to process audio files through Amazon Transcribe and Amazon Comprehend, to generate the data required for Sentiment Analysis of Contact Center calls. The steps themselves can be executed from any platform, the notebook is just convenient for step-by-step execution and experimentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial setup\n",
    "\n",
    "The libraries use some packages that are not installed by default. Install them by running the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U implicits pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving the data to the processing location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is available on the data folder. First, check that the audio files are there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../data/recordings/16KHz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell above should list 16 audio files. Now copy the audio files to the bucket we'll use during the exercise. This is needed because Amazon Transcribe expects its data source to be files on S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sm\n",
    "\n",
    "bucket = sm.Session().default_bucket()\n",
    "audio_source_path = \"audio/contact-center/16KHz\"\n",
    "print(f\"Copying files to s3://{bucket}/{audio_source_path}\")\n",
    "!aws s3 sync \"/home/ec2-user/SageMaker/transcribe-comprehend/data/recordings/16KHz/\" s3://{bucket}/{audio_source_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the files are in the right bucket and folders. The `get_recording_files` function will retrieve a list of all files in the specified bucket and path. There should be a list of only \".wav\" files as a result. If this is your result, we are ready to start transcribing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transcribe_utils import Speech, TranscriptReport, download_transcripts, get_recording_files, move_transcripts, \\\n",
    "    report_transcript, \\\n",
    "    transcribe_recording, \\\n",
    "    wait_for_jobs\n",
    "\n",
    "file_names = get_recording_files(bucket=bucket, path=audio_source_path)\n",
    "print(\"\\n\".join(file_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing the Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "transcribe = boto3.client('transcribe')\n",
    "vocabulary_name = \"dpv-cc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Vocabulary Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting the transcriptions, create a custom vocabulary to improve transcription quality. The vocabulary file was copied from the S3 backup above. Here's its contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../data/vocabularies/vocabulary\\ v1.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the following two cells to send the vocabulary to Amazon Transcribe and wait for its creation.It should take less than 2 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/vocabularies/vocabulary v1.txt\", \"r\") as f:\n",
    "    vocab_entries = f.readlines()\n",
    "vocab_entries = [entry[:-1] if entry[-1] == '\\n' else entry for entry in vocab_entries]\n",
    "\n",
    "vocab_result = transcribe.create_vocabulary(VocabularyName=vocabulary_name, LanguageCode='de-DE', Phrases=vocab_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while vocab_result['VocabularyState'] not in {\"READY\", \"FAILED\"}:\n",
    "    time.sleep(30)\n",
    "    vocab_result = transcribe.get_vocabulary(VocabularyName=vocabulary_name)\n",
    "    print(f\"Vocabulary {vocabulary_name} still {vocab_result['VocabularyState']}...\")\n",
    "    \n",
    "print(f\"Vocabulary {vocabulary_name} {vocab_result['VocabularyState']}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocabulary creation takes a few minutes, you can check the progress on the <a href=\"https://console.aws.amazon.com/transcribe/home?region=us-east-1#vocabulary\" target=\"_blank\">Amazon Transcribe Console</a>. Wait until creation is complete, then cotinue the execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Transcription Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will submit transcription jobs for all the files in the bucket and path defined above. If you want to monitor the jobs themselves, open the <a href=\"https://console.aws.amazon.com/transcribe/home?region=us-east-1#\" target=\"_blank\">Amazon Transcribe console</a> in a new tab **before executing it**.\n",
    "\n",
    "If it's the first execution, the tab should be empty. Go ahead and execute the next cell to submit the audio recordings for transcription (you will need to refresh the console tab to see the jobs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = str(int(time.time()))  # Avoiding conflicts in case of ressubmission\n",
    "base_job_name = f\"dpv-cc{ts}\"\n",
    "transcribe_jobs = []\n",
    "for i, recording in enumerate(file_names):\n",
    "    transcribe_jobs.append(\n",
    "        transcribe_recording(\n",
    "            recording, \n",
    "            job_name=f\"{base_job_name}-{i + 1:03d}\",\n",
    "            bucket=bucket,\n",
    "            path=audio_source_path,\n",
    "            VocabularyName=vocabulary_name\n",
    "        )\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell will wait for transcribe to finish all jobs and move the resulting transcripts to a proper bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "transcript_dest_path = \"transcribe-output\"\n",
    "final_job_results = wait_for_jobs(transcribe_jobs)\n",
    "move_transcripts(jobs=final_job_results, dest_bucket=bucket, dest_path=transcript_dest_path)\n",
    "pprint(final_job_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the transcriptions to the local storage to be able to see them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_transcripts_path = \"../data/transcriptions/16KHz\"\n",
    "download_transcripts(bucket, transcript_dest_path, local_transcripts_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now navigate to the `data/transcriptionns/16KHz` folder and inspect the results of the transcriptions. You'll see that they contain:\n",
    "- A full text transcription\n",
    "- A detailed word by word transcription for each channel, with start time, end time and confidence.\n",
    "- A list of segments of speech per channel, also with start and end time and the list of each word identified.\n",
    "\n",
    "While very detailed, this format is difficult to read. In the next section we'll generate some basic reports and add sentiment information to the transcriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Transcription Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will take each transcription and generate:\n",
    "- A text report with human-readable rendering of it\n",
    "- A sentiment analysis of the overall conversation\n",
    "- A detailed sentiment analysis of each segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from comprehend_utils import Sentiment, analyze_sentiment\n",
    "\n",
    "def print_transcript_report(transcript_file, report, general_sentiment, sentiments, dest_processed_file=None):\n",
    "    path = os.path.abspath(dest_processed_file if dest_processed_file else os.path.dirname(transcript_file))\n",
    "    base_name, ext = os.path.splitext(os.path.basename(transcript_file))\n",
    "    dest_file = os.path.join(path, f\"{base_name}.txt\")\n",
    "    with open(dest_file, \"w\") as dest:\n",
    "        dest.write(f\"Job:\\t\\t{report.job}\\nRecording:\\t{report.recording}\\nTranscript:\\t{base_name}{ext}\\n\"\n",
    "                   f\"Speakers:\\t{sorted(report.speakers)}\\n\")\n",
    "        dest.write(f\"Full Text:\\n{report.full_text}\\n\")\n",
    "        # noinspection PyProtectedMember\n",
    "        dest.write(f\"Sentiment: {general_sentiment.general}\"\n",
    "                   f\" ({', '.join(f'{k[:3]}={v:0.3f}' for (k, v) in general_sentiment._asdict().items() if k != 'general')})\\n\")\n",
    "        dest.write(\"\\nDialogue:\\n\")\n",
    "        for ((_, _, speaker, speech), sentiment) in zip(report.dialogue, sentiments):\n",
    "            pred_sentiment: str = sentiment.general\n",
    "            if sentiment.general == \"POSITIVE\":\n",
    "                sentiment_strength = sentiment.positive\n",
    "            elif sentiment.general == \"NEGATIVE\":\n",
    "                sentiment_strength = sentiment.negative\n",
    "            elif sentiment.general == \"NEUTRAL\":\n",
    "                sentiment_strength = sentiment.neutral\n",
    "            else:\n",
    "                sentiment_strength = sentiment.mixed\n",
    "            dest.write(f\"{speaker} ({pred_sentiment[:3].lower()}: {sentiment_strength:0.3f}): {speech}\\n\")\n",
    "\n",
    "comprehend = boto3.client('comprehend')\n",
    "dialogues = []\n",
    "for transcript in glob(f\"{local_transcripts_path}/*.json\"):\n",
    "    transcript_report = report_transcript(transcript)\n",
    "    general_sentiment = analyze_sentiment(transcript_report.full_text[:4500])\n",
    "    sentiments = analyze_sentiment([speech.speech for speech in transcript_report.dialogue])\n",
    "    print_transcript_report(transcript, transcript_report, general_sentiment, sentiments)\n",
    "    dialogues.append((transcript, transcript_report.dialogue, sentiments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can see a text file for each transcription, which contains a readable report of the conversation. Open a few of them to see the results.\n",
    "\n",
    "In order to build better visualizations, create some files from the `dialogues` list. Execute the following cells to generate an HTML page, an Excel file and a Pandas dataframe, which we will use for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def dialogues_to_df(dialogues):\n",
    "    \"\"\"\n",
    "    :param dialogues: List of transcribed dialogues with analysis. Each is (<transcript file name>, <dialogue>, <dialogue sentiment>)\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        'transcript': [],\n",
    "        'recording': [],\n",
    "        'index': [],\n",
    "        'speaker': [],\n",
    "        'pred_sent': [],\n",
    "        'speech': [],\n",
    "        'positive': [],\n",
    "        'negative': [],\n",
    "        'mixed': [],\n",
    "        'neutral': []\n",
    "    }\n",
    "    for (transcript, dialogue, sentiments) in dialogues:\n",
    "        for i, (speech, sentiment) in enumerate(zip(dialogue, sentiments)):\n",
    "            data['transcript'].append(os.path.basename(transcript))\n",
    "            data['recording'].append(speech.recording)\n",
    "            data['index'].append(i)\n",
    "            data['speaker'].append(speech.speaker)\n",
    "            data['pred_sent'].append(sentiment.general)\n",
    "            data['speech'].append(speech.speech)\n",
    "            data['positive'].append(sentiment.positive)\n",
    "            data['negative'].append(sentiment.negative)\n",
    "            data['mixed'].append(sentiment.mixed)\n",
    "            data['neutral'].append(sentiment.neutral)\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def export_df(df, export_path, export_format=\"pickle\", hdf_key=None) -> None:\n",
    "    \"\"\"\n",
    "    Exports the dataframe in a variety of formats. Dataframe is expected to have columns `transcript` and `index`\n",
    "\n",
    "    :param df: The dataframe to be exported\n",
    "    :param export_path: Where to write the exported dataframe\n",
    "    :param export_format: One of \"html\", \"csv\", \"json\", \"parquet\", \"pickle\", \"hdf\"\n",
    "    :param hdf_key: if hdf format is used, key to store the df under in the HDF5 file\n",
    "    \"\"\"\n",
    "    _, ext = os.path.splitext(export_path)\n",
    "    use_ext = '.' + export_format if len(ext) == 0 else ''\n",
    "    if export_format == \"html\":\n",
    "        color_dict = {\n",
    "            'POSITIVE': 'limegreen',\n",
    "            'NEGATIVE': 'red',\n",
    "            'NEUTRAL': 'lightgrey',\n",
    "            'MIXED': 'yellow'\n",
    "        }\n",
    "        spk_dict = {\n",
    "            'ch_0': '#F0F8FF',\n",
    "            'spk_0': '#F0F8FF',\n",
    "            'ch_1': '#FFF8DC',\n",
    "            'spk_1': '#FFF8DC'\n",
    "        }\n",
    "        df.set_index(\n",
    "            ['transcript', 'recording', 'speaker', 'index']\n",
    "        ).to_html(export_path + use_ext, encoding='utf-8',\n",
    "                  formatters={\n",
    "                      'pred_sent': lambda sent: f'<span style=\"background-color:{color_dict[sent]}\">{sent}</span>',\n",
    "                      'speaker': lambda speaker: f'<span style=\"background-color:{spk_dict[speaker]}\">{speaker}</span>'\n",
    "                  }, escape=False)\n",
    "    elif export_format == \"csv\":\n",
    "        df.to_csv(export_path + use_ext)\n",
    "    elif export_format == \"json\":\n",
    "        df.to_json(export_path + use_ext)\n",
    "    elif export_format == \"parquet\":\n",
    "        df.to_parquet(export_path + use_ext)\n",
    "    elif export_format == \"pickle\":\n",
    "        df.to_pickle(export_path + use_ext)\n",
    "    elif export_format == \"excel\":\n",
    "        if len(use_ext) > 0:\n",
    "            use_ext = '.xlsx'\n",
    "        df.to_excel(export_path + use_ext, index=False)\n",
    "    elif export_format == \"hdf\":\n",
    "        assert hdf_key is not None, \"Parameter hdf_key must be informed if export format is hdf.\"\n",
    "        df.to_hdf(export_path + use_ext, hdf_key)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown export format: {export_format}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_export_path = \"../data/results/transcription\"\n",
    "df = dialogues_to_df(dialogues)\n",
    "export_df(df, local_export_path, \"html\")\n",
    "export_df(df, local_export_path, \"pickle\")\n",
    "export_df(df, local_export_path, \"excel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all processing done, you can open the `transcript_viz` notebook. You can also look at the code inside the `transcribe_utils` package and the `comprehend_utils` package to better understand all that was done above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
