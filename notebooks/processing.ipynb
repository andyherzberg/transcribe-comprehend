{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Processing\n",
    "\n",
    "This notebook shows a basic sequence of processing steps required to process audio files through Amazon Transcribe and Amazon Comprehend, to generate the data required for Sentiment Analysis of Contact Center calls. The steps themselves can be executed from any platform, the notebook is just convenient for step-by-step execution and experimentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial setup\n",
    "\n",
    "The libraries use some packages that are not installed by default. Install them by running the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: implicits in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (1.0.2)\n",
      "Requirement already up-to-date: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (1.1.2)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.15.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from python-dateutil>=2.7.3->pandas) (1.14.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U implicits pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving the data to the processing location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is available on a backup disk. We'll first copy the files from there into  the data folder. This will also help create the required folder structure for processing and analysing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/dialogues/dpv-cc-v1-002.txt to ../data/dialogues/dpv-cc-v1-002.txt\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/dialogues/dpv-cc-v1-001.txt to ../data/dialogues/dpv-cc-v1-001.txt\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/dialogues/dpv-cc-v1-006.txt to ../data/dialogues/dpv-cc-v1-006.txt\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/dialogues/dpv-cc-v1-005.txt to ../data/dialogues/dpv-cc-v1-005.txt\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/dialogues/dpv-cc-v1-003.txt to ../data/dialogues/dpv-cc-v1-003.txt\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/dialogues/dpv-cc-v1-007.txt to ../data/dialogues/dpv-cc-v1-007.txt\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/dialogues/dpv-cc-v1-008.txt to ../data/dialogues/dpv-cc-v1-008.txt\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/16KHz/dpv-cc-v2-001.txt to ../data/transcriptions/16KHz/dpv-cc-v2-001.txt\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/16KHz/dpv-cc-v2-002.txt to ../data/transcriptions/16KHz/dpv-cc-v2-002.txt\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/results/transcription.html to ../data/results/transcription.html\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/16KHz/dpv-cc-v2-003.txt to ../data/transcriptions/16KHz/dpv-cc-v2-003.txt\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/16KHz/dpv-cc-v2-003.json to ../data/transcriptions/16KHz/dpv-cc-v2-003.json\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/16KHz/dpv-cc-v2-001.json to ../data/transcriptions/16KHz/dpv-cc-v2-001.json\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/results/transcription.xlsx to ../data/results/transcription.xlsx\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/results/transcription.pickle to ../data/results/transcription.pickle\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/16KHz/dpv-cc-v2-004.txt to ../data/transcriptions/16KHz/dpv-cc-v2-004.txt\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/16KHz/dpv-cc-v2-006.txt to ../data/transcriptions/16KHz/dpv-cc-v2-006.txt\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/16KHz/dpv-cc-v2-004.json to ../data/transcriptions/16KHz/dpv-cc-v2-004.json\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/16KHz/dpv-cc-v2-005.json to ../data/transcriptions/16KHz/dpv-cc-v2-005.json\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/16KHz/dpv-cc-v2-008.txt to ../data/transcriptions/16KHz/dpv-cc-v2-008.txt\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/16KHz/dpv-cc-v2-010.txt to ../data/transcriptions/16KHz/dpv-cc-v2-010.txt\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/16KHz/dpv-cc-v2-002.json to ../data/transcriptions/16KHz/dpv-cc-v2-002.json\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/16KHz/dpv-cc-v2-005.txt to ../data/transcriptions/16KHz/dpv-cc-v2-005.txt\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/16KHz/dpv-cc-v2-007.txt to ../data/transcriptions/16KHz/dpv-cc-v2-007.txt\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/16KHz/dpv-cc-v2-009.txt to ../data/transcriptions/16KHz/dpv-cc-v2-009.txt\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/16KHz/dpv-cc-v2-006.json to ../data/transcriptions/16KHz/dpv-cc-v2-006.json\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/16KHz/dpv-cc-v2-009.json to ../data/transcriptions/16KHz/dpv-cc-v2-009.json\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/16KHz/dpv-cc-v2-011.txt to ../data/transcriptions/16KHz/dpv-cc-v2-011.txt\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/16KHz/dpv-cc-v2-012.txt to ../data/transcriptions/16KHz/dpv-cc-v2-012.txt\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/16KHz/dpv-cc-v2-013.txt to ../data/transcriptions/16KHz/dpv-cc-v2-013.txt\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/16KHz/dpv-cc-v2-008.json to ../data/transcriptions/16KHz/dpv-cc-v2-008.json\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/16KHz/dpv-cc-v2-013.json to ../data/transcriptions/16KHz/dpv-cc-v2-013.json\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/16KHz/dpv-cc-v2-010.json to ../data/transcriptions/16KHz/dpv-cc-v2-010.json\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/16KHz/dpv-cc-v2-011.json to ../data/transcriptions/16KHz/dpv-cc-v2-011.json\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/16KHz/dpv-cc-v2-007.json to ../data/transcriptions/16KHz/dpv-cc-v2-007.json\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/16KHz/dpv-cc-v2-012.json to ../data/transcriptions/16KHz/dpv-cc-v2-012.json\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/16KHz/dpv-cc-v2-014.json to ../data/transcriptions/16KHz/dpv-cc-v2-014.json\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/16KHz/dpv-cc-v2-014.txt to ../data/transcriptions/16KHz/dpv-cc-v2-014.txt\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/16KHz/dpv-cc-v2-015.txt to ../data/transcriptions/16KHz/dpv-cc-v2-015.txt\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/16KHz/dpv-cc-v2-016.txt to ../data/transcriptions/16KHz/dpv-cc-v2-016.txt\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/8KHz/dpv-cc-v1-003.txt to ../data/transcriptions/8KHz/dpv-cc-v1-003.txt\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/8KHz/dpv-cc-v1-004.txt to ../data/transcriptions/8KHz/dpv-cc-v1-004.txt\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/8KHz/dpv-cc-v1-001.txt to ../data/transcriptions/8KHz/dpv-cc-v1-001.txt\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/16KHz/dpv-cc-v2-016.json to ../data/transcriptions/16KHz/dpv-cc-v2-016.json\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/16KHz/dpv-cc-v2-015.json to ../data/transcriptions/16KHz/dpv-cc-v2-015.json\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/8KHz/dpv-cc-v1-005.txt to ../data/transcriptions/8KHz/dpv-cc-v1-005.txt\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/8KHz/dpv-cc-v1-002.json to ../data/transcriptions/8KHz/dpv-cc-v1-002.json\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/8KHz/dpv-cc-v1-001.json to ../data/transcriptions/8KHz/dpv-cc-v1-001.json\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/8KHz/dpv-cc-v1-002.txt to ../data/transcriptions/8KHz/dpv-cc-v1-002.txt\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/8KHz/dpv-cc-v1-006.txt to ../data/transcriptions/8KHz/dpv-cc-v1-006.txt\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/8KHz/dpv-cc-v1-004.json to ../data/transcriptions/8KHz/dpv-cc-v1-004.json\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/8KHz/dpv-cc-v1-003.json to ../data/transcriptions/8KHz/dpv-cc-v1-003.json\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/8KHz/dpv-cc-v1-005.json to ../data/transcriptions/8KHz/dpv-cc-v1-005.json\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/8KHz/dpv-cc-v1-007.txt to ../data/transcriptions/8KHz/dpv-cc-v1-007.txt\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/8KHz/dpv-cc-v1-008.txt to ../data/transcriptions/8KHz/dpv-cc-v1-008.txt\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/8KHz/dpv-cc-v1-006.json to ../data/transcriptions/8KHz/dpv-cc-v1-006.json\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/8KHz/dpv-cc-v1-007.json to ../data/transcriptions/8KHz/dpv-cc-v1-007.json\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/dialogues/dpv-cc-v1-004.txt to ../data/dialogues/dpv-cc-v1-004.txt\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/8KHz/dpv-cc-v1-008.json to ../data/transcriptions/8KHz/dpv-cc-v1-008.json\n",
      "download: s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source/transcriptions/Transcriptions 16KHz recordings.zip to ../data/transcriptions/Transcriptions 16KHz recordings.zip\n",
      "01740405-e5bf-463f-bc76-1d80f6412fff.wav\n",
      "0174043c-d3a1-478a-a0ea-539c7075fb54.wav\n",
      "017404e1-995b-418c-beb4-9ead3f79a7b6.wav\n",
      "01740574-5169-4491-834e-c0cd2cd6120a.wav\n",
      "01740677-ab28-4b30-89ca-18cb17b7d56e.wav\n",
      "0174067d-f3b5-47e9-a826-b8b25239e74c.wav\n",
      "0174068b-59cc-475a-aec4-659cd3b2f107.wav\n",
      "01740694-7812-42b3-901e-c1576493d840.wav\n",
      "01740b64-94fd-4556-9cfa-2010b4187d5f.wav\n",
      "01742a46-8cc5-40bc-870d-06a3efd9fead.wav\n",
      "01742a48-9802-45f1-82aa-0be122bd76b9.wav\n",
      "01742a4a-efc9-4826-a455-ac52d1c2ff16.wav\n",
      "01742a51-965c-4acb-ad77-68e397d5ff1e.wav\n",
      "01742a57-8b54-4ca8-8412-fc62379d83b5.wav\n",
      "01742faa-dc9f-4e3f-af1d-88f9ae19c2dc.wav\n",
      "01742fb1-0d44-4239-98d7-1b924fbe94ad.wav\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p /home/ec2-user/SageMaker/transcribe-comprehend/data/\n",
    "!aws s3 sync s3://transcribe-comprehend-demo-2020-09-14-nb-audio-source /home/ec2-user/SageMaker/transcribe-comprehend/data/\n",
    "!ls ../data/Call_Sentiment_Analysis_PoC/16\\ KHz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell above should list the 16KHz audio files. Now copy the audio files to the bucket we'll use during the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sm\n",
    "\n",
    "bucket = sm.Session().default_bucket()\n",
    "audio_source_path = \"audio/contact-center/16KHz\"\n",
    "!aws s3 sync \"/home/ec2-user/SageMaker/transcribe-comprehend/data/Call_Sentiment_Analysis_PoC/16 KHz/\" s3://{bucket}/{audio_source_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the files are in the right bucket and folders. The `get_recording_files` function will retrieve a list of all files in the specified bucket and path. There should be a list of only \".wav\" files as a result. If this is your result, we are ready to start transcribing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0174043c-d3a1-478a-a0ea-539c7075fb54.wav\n",
      "017404e1-995b-418c-beb4-9ead3f79a7b6.wav\n",
      "01740574-5169-4491-834e-c0cd2cd6120a.wav\n",
      "01740677-ab28-4b30-89ca-18cb17b7d56e.wav\n",
      "0174067d-f3b5-47e9-a826-b8b25239e74c.wav\n",
      "0174068b-59cc-475a-aec4-659cd3b2f107.wav\n",
      "01740694-7812-42b3-901e-c1576493d840.wav\n",
      "01740b64-94fd-4556-9cfa-2010b4187d5f.wav\n",
      "01742a46-8cc5-40bc-870d-06a3efd9fead.wav\n",
      "01742a48-9802-45f1-82aa-0be122bd76b9.wav\n",
      "01742a4a-efc9-4826-a455-ac52d1c2ff16.wav\n",
      "01742a51-965c-4acb-ad77-68e397d5ff1e.wav\n",
      "01742a57-8b54-4ca8-8412-fc62379d83b5.wav\n",
      "01742faa-dc9f-4e3f-af1d-88f9ae19c2dc.wav\n",
      "01742fb1-0d44-4239-98d7-1b924fbe94ad.wav\n"
     ]
    }
   ],
   "source": [
    "from transcribe_utils import Speech, TranscriptReport, download_transcripts, get_recording_files, move_transcripts, \\\n",
    "    report_transcript, \\\n",
    "    transcribe_recording, \\\n",
    "    wait_for_jobs\n",
    "\n",
    "file_names = get_recording_files(bucket=bucket, path=audio_source_path)\n",
    "print(\"\\n\".join(file_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing the Transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Vocabulary Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting the transcriptions, create a custom vocabulary to improve transcription quality. The vocabulary file was copied from the S3 backup above. Here's its contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gruner-und-Jahr\n",
      "Gruner-und-Jahr-Kundenservice\n",
      "Geo\n",
      "Brigitte\n",
      "Abo\n",
      "P.M.\n",
      "Zeitschriften\n",
      "Heften\n",
      "IBAN\n",
      "BIC\n",
      "Auftragsnummer\n",
      "Botenzustellung\n",
      "Botenversand\n",
      "E-Paper\n",
      "Registrierungslink\n",
      "Schlehenweg\n",
      "Mustermannstraße\n",
      "Musterhausen\n",
      "Moorrege\n",
      "Elli-Muster\n",
      "Murmelmann\n",
      "Elise-Musterfrau\n",
      "Margitt"
     ]
    }
   ],
   "source": [
    "!cat ../data/vocabularies/vocabulary\\ v1.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the following two cells to send the vocabulary to Amazon Transcribe and wait for its creation.It should take less than 2 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import boto3\n",
    "\n",
    "vocabulary_name = \"dpv-cc\"\n",
    "with open(\"../data/vocabularies/vocabulary v1.txt\", \"r\") as f:\n",
    "    vocab_entries = f.readlines()\n",
    "vocab_entries = [entry[:-1] if entry[-1] == '\\n' else entry for entry in vocab_entries]\n",
    "transcribe = boto3.client('transcribe')\n",
    "vocab_result = transcribe.create_vocabulary(VocabularyName=vocabulary_name, LanguageCode='de-DE', Phrases=vocab_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary dpv-cc still PENDING...\n",
      "Vocabulary dpv-cc still PENDING...\n",
      "Vocabulary dpv-cc still READY...\n",
      "Vocabulary dpv-cc READY...\n"
     ]
    }
   ],
   "source": [
    "while vocab_result['VocabularyState'] not in {\"READY\", \"FAILED\"}:\n",
    "    time.sleep(30)\n",
    "    vocab_result = transcribe.get_vocabulary(VocabularyName=vocabulary_name)\n",
    "    print(f\"Vocabulary {vocabulary_name} still {vocab_result['VocabularyState']}...\")\n",
    "    \n",
    "print(f\"Vocabulary {vocabulary_name} {vocab_result['VocabularyState']}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocabulary creation takes a few minutes, you can check the progress on the <a href=\"https://console.aws.amazon.com/transcribe/home?region=us-east-1#vocabulary\" target=\"_blank\">Amazon Transcribe Console</a>. Wait until creation is complete, then cotinue the execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Transcription Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will submit transcription jobs for all the files in the bucket and path defined above. If you want to monitor the jobs themselves, open the <a href=\"https://console.aws.amazon.com/transcribe/home?region=us-east-1#\" target=\"_blank\">Amazon Transcribe console</a> in a new tab **before executing it**.\n",
    "\n",
    "If it's the first execution, the tab should be empty. Go ahead and execute the next cell to submit the audio recordings for transcription (you will need to refresh the console tab to see the jobs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting job dpv-cc1600045852-001 for s3://sagemaker-us-east-1-160951647621/audio/contact-center/16KHz/0174043c-d3a1-478a-a0ea-539c7075fb54.wav\n",
      "Starting job dpv-cc1600045852-002 for s3://sagemaker-us-east-1-160951647621/audio/contact-center/16KHz/017404e1-995b-418c-beb4-9ead3f79a7b6.wav\n",
      "Starting job dpv-cc1600045852-003 for s3://sagemaker-us-east-1-160951647621/audio/contact-center/16KHz/01740574-5169-4491-834e-c0cd2cd6120a.wav\n",
      "Starting job dpv-cc1600045852-004 for s3://sagemaker-us-east-1-160951647621/audio/contact-center/16KHz/01740677-ab28-4b30-89ca-18cb17b7d56e.wav\n",
      "Starting job dpv-cc1600045852-005 for s3://sagemaker-us-east-1-160951647621/audio/contact-center/16KHz/0174067d-f3b5-47e9-a826-b8b25239e74c.wav\n",
      "Starting job dpv-cc1600045852-006 for s3://sagemaker-us-east-1-160951647621/audio/contact-center/16KHz/0174068b-59cc-475a-aec4-659cd3b2f107.wav\n",
      "Starting job dpv-cc1600045852-007 for s3://sagemaker-us-east-1-160951647621/audio/contact-center/16KHz/01740694-7812-42b3-901e-c1576493d840.wav\n",
      "Starting job dpv-cc1600045852-008 for s3://sagemaker-us-east-1-160951647621/audio/contact-center/16KHz/01740b64-94fd-4556-9cfa-2010b4187d5f.wav\n",
      "Starting job dpv-cc1600045852-009 for s3://sagemaker-us-east-1-160951647621/audio/contact-center/16KHz/01742a46-8cc5-40bc-870d-06a3efd9fead.wav\n",
      "Starting job dpv-cc1600045852-010 for s3://sagemaker-us-east-1-160951647621/audio/contact-center/16KHz/01742a48-9802-45f1-82aa-0be122bd76b9.wav\n",
      "Starting job dpv-cc1600045852-011 for s3://sagemaker-us-east-1-160951647621/audio/contact-center/16KHz/01742a4a-efc9-4826-a455-ac52d1c2ff16.wav\n",
      "Starting job dpv-cc1600045852-012 for s3://sagemaker-us-east-1-160951647621/audio/contact-center/16KHz/01742a51-965c-4acb-ad77-68e397d5ff1e.wav\n",
      "Starting job dpv-cc1600045852-013 for s3://sagemaker-us-east-1-160951647621/audio/contact-center/16KHz/01742a57-8b54-4ca8-8412-fc62379d83b5.wav\n",
      "Starting job dpv-cc1600045852-014 for s3://sagemaker-us-east-1-160951647621/audio/contact-center/16KHz/01742faa-dc9f-4e3f-af1d-88f9ae19c2dc.wav\n",
      "Starting job dpv-cc1600045852-015 for s3://sagemaker-us-east-1-160951647621/audio/contact-center/16KHz/01742fb1-0d44-4239-98d7-1b924fbe94ad.wav\n"
     ]
    }
   ],
   "source": [
    "ts = str(int(time.time()))  # Avoiding conflicts in case of ressubmission\n",
    "base_job_name = f\"dpv-cc{ts}\"\n",
    "transcribe_jobs = []\n",
    "for i, recording in enumerate(file_names):\n",
    "    transcribe_jobs.append(\n",
    "        transcribe_recording(\n",
    "            recording, \n",
    "            job_name=f\"{base_job_name}-{i + 1:03d}\",\n",
    "            bucket=bucket,\n",
    "            path=audio_source_path,\n",
    "            VocabularyName=vocabulary_name\n",
    "        )\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell will wait for transcribe to finish all jobs and move the resulting transcripts to a proper bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting\n",
      "At least one in progress, wait more\n",
      "At least one in progress, wait more\n",
      "At least one in progress, wait more\n",
      "At least one in progress, wait more\n",
      "At least one in progress, wait more\n",
      "Job dpv-cc1600045852-001 finished with status COMPLETED\n",
      "\tMedia: s3://sagemaker-us-east-1-160951647621/audio/contact-center/16KHz/0174043c-d3a1-478a-a0ea-539c7075fb54.wav\n",
      "\tTranscript: https://s3.us-east-1.amazonaws.com/sagemaker-us-east-1-160951647621/dpv-cc1600045852-001.json\n",
      "\n",
      "Job dpv-cc1600045852-002 finished with status COMPLETED\n",
      "\tMedia: s3://sagemaker-us-east-1-160951647621/audio/contact-center/16KHz/017404e1-995b-418c-beb4-9ead3f79a7b6.wav\n",
      "\tTranscript: https://s3.us-east-1.amazonaws.com/sagemaker-us-east-1-160951647621/dpv-cc1600045852-002.json\n",
      "\n",
      "Job dpv-cc1600045852-003 finished with status COMPLETED\n",
      "\tMedia: s3://sagemaker-us-east-1-160951647621/audio/contact-center/16KHz/01740574-5169-4491-834e-c0cd2cd6120a.wav\n",
      "\tTranscript: https://s3.us-east-1.amazonaws.com/sagemaker-us-east-1-160951647621/dpv-cc1600045852-003.json\n",
      "\n",
      "Job dpv-cc1600045852-004 finished with status COMPLETED\n",
      "\tMedia: s3://sagemaker-us-east-1-160951647621/audio/contact-center/16KHz/01740677-ab28-4b30-89ca-18cb17b7d56e.wav\n",
      "\tTranscript: https://s3.us-east-1.amazonaws.com/sagemaker-us-east-1-160951647621/dpv-cc1600045852-004.json\n",
      "\n",
      "Job dpv-cc1600045852-005 finished with status COMPLETED\n",
      "\tMedia: s3://sagemaker-us-east-1-160951647621/audio/contact-center/16KHz/0174067d-f3b5-47e9-a826-b8b25239e74c.wav\n",
      "\tTranscript: https://s3.us-east-1.amazonaws.com/sagemaker-us-east-1-160951647621/dpv-cc1600045852-005.json\n",
      "\n",
      "Job dpv-cc1600045852-006 finished with status COMPLETED\n",
      "\tMedia: s3://sagemaker-us-east-1-160951647621/audio/contact-center/16KHz/0174068b-59cc-475a-aec4-659cd3b2f107.wav\n",
      "\tTranscript: https://s3.us-east-1.amazonaws.com/sagemaker-us-east-1-160951647621/dpv-cc1600045852-006.json\n",
      "\n",
      "Job dpv-cc1600045852-007 finished with status COMPLETED\n",
      "\tMedia: s3://sagemaker-us-east-1-160951647621/audio/contact-center/16KHz/01740694-7812-42b3-901e-c1576493d840.wav\n",
      "\tTranscript: https://s3.us-east-1.amazonaws.com/sagemaker-us-east-1-160951647621/dpv-cc1600045852-007.json\n",
      "\n",
      "Job dpv-cc1600045852-008 finished with status COMPLETED\n",
      "\tMedia: s3://sagemaker-us-east-1-160951647621/audio/contact-center/16KHz/01740b64-94fd-4556-9cfa-2010b4187d5f.wav\n",
      "\tTranscript: https://s3.us-east-1.amazonaws.com/sagemaker-us-east-1-160951647621/dpv-cc1600045852-008.json\n",
      "\n",
      "Job dpv-cc1600045852-009 finished with status COMPLETED\n",
      "\tMedia: s3://sagemaker-us-east-1-160951647621/audio/contact-center/16KHz/01742a46-8cc5-40bc-870d-06a3efd9fead.wav\n",
      "\tTranscript: https://s3.us-east-1.amazonaws.com/sagemaker-us-east-1-160951647621/dpv-cc1600045852-009.json\n",
      "\n",
      "Job dpv-cc1600045852-010 finished with status COMPLETED\n",
      "\tMedia: s3://sagemaker-us-east-1-160951647621/audio/contact-center/16KHz/01742a48-9802-45f1-82aa-0be122bd76b9.wav\n",
      "\tTranscript: https://s3.us-east-1.amazonaws.com/sagemaker-us-east-1-160951647621/dpv-cc1600045852-010.json\n",
      "\n",
      "Job dpv-cc1600045852-011 finished with status COMPLETED\n",
      "\tMedia: s3://sagemaker-us-east-1-160951647621/audio/contact-center/16KHz/01742a4a-efc9-4826-a455-ac52d1c2ff16.wav\n",
      "\tTranscript: https://s3.us-east-1.amazonaws.com/sagemaker-us-east-1-160951647621/dpv-cc1600045852-011.json\n",
      "\n",
      "Job dpv-cc1600045852-012 finished with status COMPLETED\n",
      "\tMedia: s3://sagemaker-us-east-1-160951647621/audio/contact-center/16KHz/01742a51-965c-4acb-ad77-68e397d5ff1e.wav\n",
      "\tTranscript: https://s3.us-east-1.amazonaws.com/sagemaker-us-east-1-160951647621/dpv-cc1600045852-012.json\n",
      "\n",
      "Job dpv-cc1600045852-013 finished with status COMPLETED\n",
      "\tMedia: s3://sagemaker-us-east-1-160951647621/audio/contact-center/16KHz/01742a57-8b54-4ca8-8412-fc62379d83b5.wav\n",
      "\tTranscript: https://s3.us-east-1.amazonaws.com/sagemaker-us-east-1-160951647621/dpv-cc1600045852-013.json\n",
      "\n",
      "Job dpv-cc1600045852-014 finished with status COMPLETED\n",
      "\tMedia: s3://sagemaker-us-east-1-160951647621/audio/contact-center/16KHz/01742faa-dc9f-4e3f-af1d-88f9ae19c2dc.wav\n",
      "\tTranscript: https://s3.us-east-1.amazonaws.com/sagemaker-us-east-1-160951647621/dpv-cc1600045852-014.json\n",
      "\n",
      "Job dpv-cc1600045852-015 finished with status COMPLETED\n",
      "\tMedia: s3://sagemaker-us-east-1-160951647621/audio/contact-center/16KHz/01742fb1-0d44-4239-98d7-1b924fbe94ad.wav\n",
      "\tTranscript: https://s3.us-east-1.amazonaws.com/sagemaker-us-east-1-160951647621/dpv-cc1600045852-015.json\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pprint' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-bd268d706993>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfinal_job_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait_for_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscribe_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmove_transcripts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinal_job_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest_bucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbucket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranscript_dest_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_job_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pprint' is not defined"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "transcript_dest_path = \"transcribe-output\"\n",
    "final_job_results = wait_for_jobs(transcribe_jobs)\n",
    "move_transcripts(jobs=final_job_results, dest_bucket=bucket, dest_path=transcript_dest_path)\n",
    "pprint(final_job_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the transcriptions to the local storage to be able to see them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading transcribe-output/dpv-cc1600045852-001.json into ../data/transcriptions/16KHz/dpv-cc1600045852-001.json\n",
      "Downloading transcribe-output/dpv-cc1600045852-002.json into ../data/transcriptions/16KHz/dpv-cc1600045852-002.json\n",
      "Downloading transcribe-output/dpv-cc1600045852-003.json into ../data/transcriptions/16KHz/dpv-cc1600045852-003.json\n",
      "Downloading transcribe-output/dpv-cc1600045852-004.json into ../data/transcriptions/16KHz/dpv-cc1600045852-004.json\n",
      "Downloading transcribe-output/dpv-cc1600045852-005.json into ../data/transcriptions/16KHz/dpv-cc1600045852-005.json\n",
      "Downloading transcribe-output/dpv-cc1600045852-006.json into ../data/transcriptions/16KHz/dpv-cc1600045852-006.json\n",
      "Downloading transcribe-output/dpv-cc1600045852-007.json into ../data/transcriptions/16KHz/dpv-cc1600045852-007.json\n",
      "Downloading transcribe-output/dpv-cc1600045852-008.json into ../data/transcriptions/16KHz/dpv-cc1600045852-008.json\n",
      "Downloading transcribe-output/dpv-cc1600045852-009.json into ../data/transcriptions/16KHz/dpv-cc1600045852-009.json\n",
      "Downloading transcribe-output/dpv-cc1600045852-010.json into ../data/transcriptions/16KHz/dpv-cc1600045852-010.json\n",
      "Downloading transcribe-output/dpv-cc1600045852-011.json into ../data/transcriptions/16KHz/dpv-cc1600045852-011.json\n",
      "Downloading transcribe-output/dpv-cc1600045852-012.json into ../data/transcriptions/16KHz/dpv-cc1600045852-012.json\n",
      "Downloading transcribe-output/dpv-cc1600045852-013.json into ../data/transcriptions/16KHz/dpv-cc1600045852-013.json\n",
      "Downloading transcribe-output/dpv-cc1600045852-014.json into ../data/transcriptions/16KHz/dpv-cc1600045852-014.json\n",
      "Downloading transcribe-output/dpv-cc1600045852-015.json into ../data/transcriptions/16KHz/dpv-cc1600045852-015.json\n"
     ]
    }
   ],
   "source": [
    "local_transcripts_path = \"../data/transcriptions/16KHz\"\n",
    "download_transcripts(bucket, transcript_dest_path, local_transcripts_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now navigate to the `data/transcriptionns/16KHz` folder and inspect the results of the transcriptions. You'll see that they contain:\n",
    "- A full text transcription\n",
    "- A detailed word by word transcription for each channel, with start time, end time and confidence.\n",
    "- A list of segments of speech per channel, also with start and end time and the list of each word identified.\n",
    "\n",
    "While very detailed, this format is difficult to read. In the next section we'll generate some basic reports and add sentiment information to the transcriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Transcription Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will take each transcription and generate:\n",
    "- A text report with human-readable rendering of it\n",
    "- A sentiment analysis of the overall conversation\n",
    "- A detailed sentiment analysis of each segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from comprehend_utils import Sentiment, analyze_sentiment\n",
    "\n",
    "def print_transcript_report(transcript_file, report, general_sentiment, sentiments, dest_processed_file=None):\n",
    "    path = os.path.abspath(dest_processed_file if dest_processed_file else os.path.dirname(transcript_file))\n",
    "    base_name, ext = os.path.splitext(os.path.basename(transcript_file))\n",
    "    dest_file = os.path.join(path, f\"{base_name}.txt\")\n",
    "    with open(dest_file, \"w\") as dest:\n",
    "        dest.write(f\"Job:\\t\\t{report.job}\\nRecording:\\t{report.recording}\\nTranscript:\\t{base_name}{ext}\\n\"\n",
    "                   f\"Speakers:\\t{sorted(report.speakers)}\\n\")\n",
    "        dest.write(f\"Full Text:\\n{report.full_text}\\n\")\n",
    "        # noinspection PyProtectedMember\n",
    "        dest.write(f\"Sentiment: {general_sentiment.general}\"\n",
    "                   f\" ({', '.join(f'{k[:3]}={v:0.3f}' for (k, v) in general_sentiment._asdict().items() if k != 'general')})\\n\")\n",
    "        dest.write(\"\\nDialogue:\\n\")\n",
    "        for ((_, _, speaker, speech), sentiment) in zip(report.dialogue, sentiments):\n",
    "            pred_sentiment: str = sentiment.general\n",
    "            if sentiment.general == \"POSITIVE\":\n",
    "                sentiment_strength = sentiment.positive\n",
    "            elif sentiment.general == \"NEGATIVE\":\n",
    "                sentiment_strength = sentiment.negative\n",
    "            elif sentiment.general == \"NEUTRAL\":\n",
    "                sentiment_strength = sentiment.neutral\n",
    "            else:\n",
    "                sentiment_strength = sentiment.mixed\n",
    "            dest.write(f\"{speaker} ({pred_sentiment[:3].lower()}: {sentiment_strength:0.3f}): {speech}\\n\")\n",
    "\n",
    "comprehend = boto3.client('comprehend')\n",
    "dialogues = []\n",
    "for transcript in glob(f\"{local_transcripts_path}/*.json\"):\n",
    "    transcript_report = report_transcript(transcript)\n",
    "    general_sentiment = analyze_sentiment(transcript_report.full_text[:4500])\n",
    "    sentiments = analyze_sentiment([speech.speech for speech in transcript_report.dialogue])\n",
    "    print_transcript_report(transcript, transcript_report, general_sentiment, sentiments)\n",
    "    dialogues.append((transcript, transcript_report.dialogue, sentiments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can see a text file for each transcription, which contains a readable report of the conversation. Open a few of them to see the results.\n",
    "\n",
    "In order to build better visualizations, create some files from the `dialogues` list. Execute the following cells to generate an HTML page, an Excel file and a Pandas dataframe, which we will use for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def dialogues_to_df(dialogues):\n",
    "    \"\"\"\n",
    "    :param dialogues: List of transcribed dialogues with analysis. Each is (<transcript file name>, <dialogue>, <dialogue sentiment>)\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        'transcript': [],\n",
    "        'recording': [],\n",
    "        'index': [],\n",
    "        'speaker': [],\n",
    "        'pred_sent': [],\n",
    "        'speech': [],\n",
    "        'positive': [],\n",
    "        'negative': [],\n",
    "        'mixed': [],\n",
    "        'neutral': []\n",
    "    }\n",
    "    for (transcript, dialogue, sentiments) in dialogues:\n",
    "        for i, (speech, sentiment) in enumerate(zip(dialogue, sentiments)):\n",
    "            data['transcript'].append(os.path.basename(transcript))\n",
    "            data['recording'].append(speech.recording)\n",
    "            data['index'].append(i)\n",
    "            data['speaker'].append(speech.speaker)\n",
    "            data['pred_sent'].append(sentiment.general)\n",
    "            data['speech'].append(speech.speech)\n",
    "            data['positive'].append(sentiment.positive)\n",
    "            data['negative'].append(sentiment.negative)\n",
    "            data['mixed'].append(sentiment.mixed)\n",
    "            data['neutral'].append(sentiment.neutral)\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def export_df(df, export_path, export_format=\"pickle\", hdf_key=None) -> None:\n",
    "    \"\"\"\n",
    "    Exports the dataframe in a variety of formats. Dataframe is expected to have columns `transcript` and `index`\n",
    "\n",
    "    :param df: The dataframe to be exported\n",
    "    :param export_path: Where to write the exported dataframe\n",
    "    :param export_format: One of \"html\", \"csv\", \"json\", \"parquet\", \"pickle\", \"hdf\"\n",
    "    :param hdf_key: if hdf format is used, key to store the df under in the HDF5 file\n",
    "    \"\"\"\n",
    "    _, ext = os.path.splitext(export_path)\n",
    "    use_ext = '.' + export_format if len(ext) == 0 else ''\n",
    "    if export_format == \"html\":\n",
    "        color_dict = {\n",
    "            'POSITIVE': 'limegreen',\n",
    "            'NEGATIVE': 'red',\n",
    "            'NEUTRAL': 'lightgrey',\n",
    "            'MIXED': 'yellow'\n",
    "        }\n",
    "        spk_dict = {\n",
    "            'ch_0': '#F0F8FF',\n",
    "            'spk_0': '#F0F8FF',\n",
    "            'ch_1': '#FFF8DC',\n",
    "            'spk_1': '#FFF8DC'\n",
    "        }\n",
    "        df.set_index(\n",
    "            ['transcript', 'recording', 'speaker', 'index']\n",
    "        ).to_html(export_path + use_ext, encoding='utf-8',\n",
    "                  formatters={\n",
    "                      'pred_sent': lambda sent: f'<span style=\"background-color:{color_dict[sent]}\">{sent}</span>',\n",
    "                      'speaker': lambda speaker: f'<span style=\"background-color:{spk_dict[speaker]}\">{speaker}</span>'\n",
    "                  }, escape=False)\n",
    "    elif export_format == \"csv\":\n",
    "        df.to_csv(export_path + use_ext)\n",
    "    elif export_format == \"json\":\n",
    "        df.to_json(export_path + use_ext)\n",
    "    elif export_format == \"parquet\":\n",
    "        df.to_parquet(export_path + use_ext)\n",
    "    elif export_format == \"pickle\":\n",
    "        df.to_pickle(export_path + use_ext)\n",
    "    elif export_format == \"excel\":\n",
    "        if len(use_ext) > 0:\n",
    "            use_ext = '.xlsx'\n",
    "        df.to_excel(export_path + use_ext, index=False)\n",
    "    elif export_format == \"hdf\":\n",
    "        assert hdf_key is not None, \"Parameter hdf_key must be informed if export format is hdf.\"\n",
    "        df.to_hdf(export_path + use_ext, hdf_key)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown export format: {export_format}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_export_path = \"../data/results/transcription\"\n",
    "df = dialogues_to_df(dialogues)\n",
    "export_df(df, local_export_path, \"html\")\n",
    "export_df(df, local_export_path, \"pickle\")\n",
    "export_df(df, local_export_path, \"excel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all processing done, you can open the `transcript_viz` notebook. You can also look at the code inside the `transcribe_utils` package and the `comprehend_utils` package to better understand all that was done above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
